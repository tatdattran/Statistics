---
title: "Aufgabe 5: t-Tests für abhängige Stichproben"
output: html_notebook
---

## Aufgabenstellung

1)	Hypothese 
2)	Voraussetzungen des t-Tests für abhängige Stichproben
3)	Grundlegende Konzepte: Was ist t-Test für abhängige Stichproben?
4)	Deskriptive Statistiken und Korrelation
5)	Ergebnisse des t-Tests für abhängige Stichproben
6)	Berechnung der Effektstärke
7)	Eine Aussage


Ziel der Studie ist es herauszufinden, ob es nach Anwendung von Diätmethoden zu einer Gewichtsabnahme kommt.
Dazu wird der t-Test für abhängige Stichproben verwendet.

Datensatz: foodDiet.csv<br>
Variable1: pre.weight<br>
Varibale2: weight6weeks<br>



**Packages**
```{r}
library(psych) # -> Deskriptive Statistiken
library(dplyr)
library(car) # -> QQ - Diagramm & Scatterplot
library(ggplot2)
```

**Datensatz vorbereiten**

```{r}
foodDiet = read.csv("foodDiet.csv")
head(foodDiet)
```

## 1) Hypothese

H1: Es gibt einen Gewichtsverlust nach 6 Wochen.<br>

H0: Es gibt keinen Gewichtsverlust nach 6 Wochen.

## 2) Voraussetzungen des t-Tests für abhängige Stichproben

- Die abhängige Variablen sind intervallskaliert: Ja, pre.weight und weight6weeks

- Es liegen zwei verbundene Stichproben oder Gruppen (pre.weight und weight6weeks) vor, aber die verschiedenen Messwertpaare sind voneinander unabhängig. 
  1) Sie sind verbundenen durch ein Person, 
  2) aber unabhängige, weil es zwei verschiedene Zeiten sind.

- Die Unterschiede zwischen den verbundenen Testwerten sind in der Grundgesamtheit normalverteilt -> siehe Histogramm oder qqPlot


**Erzeuge der neuen Variable "Differenz"**

```{r}
# Differenz ausrechnen
zwischen <- foodDiet$weight6weeks - foodDiet$pre.weight

# Die Spalte "Differenz" wird zum Datensatz hinzugefügt
foodDiet <- cbind(foodDiet, "Differenz" = zwischen)
foodDiet$Differenz <- as.numeric(foodDiet$Differenz)

head(foodDiet)
```
**Separate Diet**

```{r}
df1 = subset(foodDiet, foodDiet$Diet == 1)
df2 = subset(foodDiet, foodDiet$Diet == 2)
df3 = subset(foodDiet, foodDiet$Diet == 3)
```

### Histogramm zur Prüfung des Normalverteilung
```{r}
colorchooose = c("darkblue", "red", "green") 
```


```{r}
g = df1$Differenz
m<-mean(g)
std<-sqrt(var(g))
hist(g, density=20, breaks=9, prob=TRUE, 
     xlab="Differenz in kg", 
     ylim=c(0, .3), 
     col = "lightblue",
     main="Histogramm des Differenz nach 6 Wochen mit Diet 1")
curve(dnorm(x, mean=m, sd=std), 
      col=colorchooose[1], lwd=2, add=TRUE, yaxt="n")
```
```{r}
g = df2$Differenz
m<-mean(g)
std<-sqrt(var(g))
hist(g, density=20, breaks=9, prob=TRUE, 
     xlab="Differenz in kg", 
     ylim=c(0, .3), 
     col = "lightblue",
     main="Histogramm des Differenz nach 6 Wochen mit Diet 2")
curve(dnorm(x, mean=m, sd=std), 
      col=colorchooose[2], lwd=2, add=TRUE, yaxt="n")
```
```{r}
g = df3$Differenz
m<-mean(g)
std<-sqrt(var(g))
hist(g, density=20, breaks=9, prob=TRUE, 
     xlab="Differenz in kg", 
     ylim=c(0, .3), 
     col = "lightblue",
     main="Histogramm des Differenz nach 6 Wochen mit Diet 3")
curve(dnorm(x, mean=m, sd=std), 
      col=colorchooose[3], lwd=2, add=TRUE, yaxt="n")
```
**Alternative**
```{r}
foodDiet %>%
  group_by(Diet) %>%
  ggplot(aes(Differenz, color=Diet)) + 
  geom_histogram(aes(fill = Diet), bins = 9) +
  facet_wrap(~Diet) +
  theme_grey()+
  labs(x= "Differenz in kg",y = "Anzahl" )
```

Die Normalverteilung ist  nicht eindeutig von Histogram. Daher kann ein QQ-Plot zur bessern Einschätzung verwendet werden.


### QQ-Diagramm zur Prüfung des Normalverteilung

Die Werte werden der Größe nach geordnet. Als Vergleich dienen die Quantile der theoretischen Verteilung, die dem entsprechenden Verteilungswert zugehören.
Wenn die Merkmalswerte aus der Vergleichsverteilung stammen, stimmen die empirischen und die theoretischen Quantile annähernd überein, d. h. die Werte liegen auf einer Diagonalen.

Große systematische Abweichungen von dieser Diagonalen geben einen Hinweis darauf, dass sich die theoretische und empirische Verteilung voneinander unterscheiden. 
DSie Werte müssen entlang einer aufsteigenden Gerade liegen, sodass eine ähnliche Verteilung vermutet werden kann.

```{r}
qqPlot(df1$Differenz, main = "QQPlot für die Var. Differenz mit Diet 1", col = colorchooose[1], ylab = "Differenz")
```

```{r}
qqPlot(df2$Differenz, main = "QQPlot für die Var. Differenz mit Diet 2", col = colorchooose[2], ylab = "Differenz")
```


```{r}
qqPlot(df3$Differenz, main = "QQPlot für die Var. Differenz mit Diet 3", col = colorchooose[3], ylab = "Differenz")
```
Es liegt eine Normalverteilung auf alle 3 Fallen vor. 

## 3)	Grundlegende Konzepte: Was ist t-Test für abhängige Stichproben?
Der t-Test für eine Stichprobe prüft anhand des Mittelwertes einer Stichprobe, ob der Mittelwert einer Grundgesamtheit gleich einem vorgegebenen Wert ist (bzw. kleiner oder größer).
Die Fragestellung des t-Tests für eine Stichprobe wird oft so verkürzt:
"Unterscheiden sich die Mittelwerte zwischen Grundgesamtheit und Stichprobe?"

Der t-Test für abhängige Stichproben testet, ob die Mittelwerte zweier abhängiger Stichproben verschieden sind. Von "abhängigen Stichproben" respektive "verbundenen Stichproben" wird gesprochen, wenn ein Messwert in einer Stichprobe und ein bestimmter Messwert in einer anderen Stichprobe sich gegenseitig beeinflussen.


## 4) Deskriptive Statistiken und Korrelation

### Korrelation

#### Streudiagramm


Ein Streudiagramm, auch Punktwolke genannt (engl. scatter plot), ist die graphische Darstellung von beobachteten Wertepaaren zweier statistischer Merkmale. Diese Wertepaare werden in ein kartesisches Koordinatensystem eingetragen, wodurch sich eine Punktwolke ergibt.




```{r}
scatterplot(df1$weight6weeks ~ df1$pre.weight, 
            main = "Streudiagramm für die Gewicht mit Diet 1", ylab = "Gewicht nach 6 Wochen.", xlab= "Gewicht vor 6 Wochhen.", col= colorchooose[1] )
```
```{r}
scatterplot(df2$weight6weeks ~ df2$pre.weight, 
            main = "Streudiagramm für die Gewicht mit Diet 2", ylab = "Gewicht nach 6 Wochen.", xlab= "Gewicht vor 6 Wochhen.", col= colorchooose[2] )
```


```{r}
scatterplot(df3$weight6weeks ~ df3$pre.weight, 
            main = "Streudiagramm für die Gewicht mit Diet 3", ylab = "Gewicht nach 6 Wochen.", xlab= "Gewicht vor 6 Wochhen.", col= colorchooose[3] )
```
Es liegt eine positiver-linearer Zusammenhang zwichen dem Gewicht vor der Diät und dem Gewicht nach der Diät vor. 

#### Korrelation nach Bravais-Pearson

Der Korrelationskoeffizient kann nur Werte im Bereich zwischen $-1$ und $+1$ annehmen. Ist er kleiner als Null ($r < 0$), so besteht ein negativer linearer Zusammenhang. Bei einem Wert grösser als Null ($r > 0$) besteht ein positiver linearer Zusammenhang und bei einem Wert von Null ($r = 0$) besteht kein Zusammenhang zwischen den Variablen.

```{r}
test1 <- cor.test(df1$weight6weeks,df1$pre.weight)
test1
```

```{r}
test2 <- cor.test(df2$weight6weeks,df2$pre.weight)
test2
```

```{r}
test3 <- cor.test(df3$weight6weeks,df3$pre.weight)
test3
```

Es wird ersichtlich, dass ein Zusammenhang zwischen weight6weeks und pre.weight auf alle 3 Fallen ($r1 = 0.9643656, p1 = .000, n1 = 24; r2 = 0.9692021, p2 = .000, n2 = 27; r3 = 0.9574649, p3 = .000, n3 = 27$) vorliegt. Da $r$ einen positiven Wert aufweist, kann von einem positiven linearen und signifikanten Zusammenhang zwischen weight6weeks und pre.weight ausgegangen werden. Für das Beispiel ergibt sich eine starke Korrelation von $r$.

### Deskriptive Statistiken


```{r}
describe(df1)
```


- pre.weight:($M=72.88, SD=	8.38, n= 24$),<br>

- weight6weeks: ($M=69.58, SD = 8.40, n= 24$)

Daher liegt die Vermutung nahe, dass der Mittelwert von pre.weight größer ist als der Mittelwert von weight6weeks von Diet 1.

```{r}
describe(df2)
```

- pre.weight:($M=71.11, SD=	10.09, n= 27$),<br>

- weight6weeks: ($M=68.09, SD = 10.22, n= 27$)

Daher liegt die Vermutung nahe, dass der Mittelwert von pre.weight größer ist als der Mittelwert von weight6weeks von Diet 2.
```{r}
describe(df3)
```

+ pre.weight:($M=73.63, SD=	7.61, n= 27$),<br>
+ weight6weeks: ($M=68.48, SD = 8.24, n= 27$)

Daher liegt die Vermutung nahe, dass der Mittelwert von pre.weight größer ist als der Mittelwert von weight6weeks von Diet 3.

## 5) Ergebnisse des t-Tests für abhängige Stichproben


**alternative = "greater"**  verwendet eine gerichtete Hypothese. 

**paired = TRUE** ist dann abzuwenden, wenn die Stichprobe verbunden ist. 

Das **"conf.level = .95"** beschreibt, dass ein Alphanivau von 0.05 verwendet wird. 

```{r}
testVER1<- t.test(df1$pre.weight , df1$weight6weeks, alternative = "greater", paired = TRUE, conf.level = .95)
testVER1
```


Die Teststatistik beträgt $t = 7.2168$ und der zugehoerige Signifikanzwert $p = 1.198e-07$. Damit gibt es einen signifikanten Gewichtverlust.  ($t(23) = 7.2168, p = 1.198e-07, n= 24$).


```{r}
testVER2<- t.test(df2$pre.weight , df2$weight6weeks, alternative = "greater", paired = TRUE, conf.level = .95)
testVER2
```
Die Teststatistik beträgt $t = 6.231$ und der zugehoerige Signifikanzwert $p = 6.802e-07$. Damit gibt es einen signifikanten Gewichtverlust.  ($t(26) = 6.231, p = 6.802e-07, n= 27$).

```{r}
testVER3<- t.test(df3$pre.weight , df3$weight6weeks, alternative = "greater", paired = TRUE, conf.level = .95)
testVER3
```
Die Teststatistik beträgt $t = 11.167$ und der zugehoerige Signifikanzwert $p = 1.015e-11$. Damit gibt es einen signifikanten Gewichtverlust.  ($t(26) = 11.167, p = 1.015e-11, n= 27$).

## 6) Berechnung der Effektstärke

Die Effektstärke ist ein Maß für die Stärke eines Treatments bzw. Phänomens. Effektstärken sind damit eine der wichtigsten Größen in empirischen Studien. Zur Einschätzung der praktischen Bedeutsamkeit existieren verschiedene Effektstärkemaße, die bei der Interpretation der Größe eines Effektes helfen.

$$r=\sqrt{\frac{t^2}{t^2+df}}$$


```{r}
eff1 <- abs(sqrt(testVER1$statistic ^2/ (testVER1$statistic^2 + testVER1$parameter)))
sprintf("Effektstärke mit Diet 1: %.4f",eff1)
```

```{r}
eff2 <- abs(sqrt(testVER2$statistic ^2/ (testVER2$statistic^2 + testVER2$parameter)))
sprintf("Effektstärke mit Diet 2: %.4f",eff2)
```

```{r}
eff3 <- abs(sqrt(testVER3$statistic ^2/ (testVER3$statistic^2 + testVER3$parameter)))
sprintf("Effektstärke mit Diet 3: %.4f",eff3)
```

Zur Beurteilung der Groesse des Effektes dient die Einteilung von Cohen (1992):
$$
\begin{align}
\text{Schwacher Effekt: } 0.10 &< ||r|| < 0.30             \\
\text{Schwacher bis mittlerer Effekt: } 0.30 &= ||r||      \\
\text{Mittlerer Effekt: } 0.30 &< ||r|| < 0.50             \\
\text{Mittlerer bis starker Effekt: }0.50 &= ||r||         \\
\text{Starker Effekt: } 0.50 &< ||r||        
\end{align}
$$
Damit liegt sehr starken Effekt vor ($r1= 0.8329, r2= 0.7739, r3= 0.9097$).



## 7) Eine Aussage

Es zeigt sich, dass ein statistisch signifikaner Gewichtverlust nach allen Diäten vorliegt ($t1(23) = 7.2168, p1 = 1.198e-07; t2(26) = 6.231, p2 = 6.802e-07; t3(26) = 11.167, p3 = 1.015e-11$). Es gibt einen Unterschied bei dem Mittwelwert des Gewichts vor der Diät und nach sechs Monaten nach der Diät. 

Diät 1:
+ pre.weight:($M=72.88, SD=	8.38, n= 24$),<br>
+ weight6weeks: ($M=69.58, SD = 8.40, n= 24$)

Diät 2:
+ pre.weight:($M=71.11, SD=	10.09, n= 27$),<br>
+ weight6weeks: ($M=68.09, SD = 10.22, n= 27$)

Diät 3:
+ pre.weight:($M=73.63, SD=	7.61, n= 27$),<br>
+ weight6weeks: ($M=68.48, SD = 8.24, n= 27$)

**H0 wird auf jeden Fall abgelehnt**

Mit dem t-Test für abhängige Stichproben werden die Unterschiede der beiden Variablen/Messzeitpunkte untersucht. Um den Effekt der einzelnen Diäten zu überprüfen sind hier einzelne t-Tests durchgeführt worden, die in diesem Fall alle signifikant waren. Genauer könnten die Haupteffekte der Diäten mit einer ANOVA untersucht werden, hier werden auch nur mehrere t-tests durchgeführt.


























